==================================================
  
 Multi-State Surface Learning (MSLearn) Package
  
==================================================
Authors: Yinan Shu, Donald G. Truhlar
        University of Minnesota
Version: 1.0
         Updated on Feb 14, 2025
  
Features of current version
    Available coordinate files:
        general, xyz, canonical_xyz
    Available network architecture: 
        feed-forward neural network
        message-passing neural network
    Available molecular representation:
        xyz, zmatrix, distance
        permutation invaraint polynomials (PIPs) of distances,
        graph
    Available methods:
        diabatization by deep neural network (DDNN)
        compatibilization by deep neural network (CDNN)
            with controllable matrix form
  
    physical properties:
        1. using permutation invariant molecular representation or
           a permuted database to constrain or restrain permutation symmetry
        2. using parametrically managed activation function to enforce
           correct behavior of potential energy surfaces (PESs) in asymptotic
           and/or repulsive regions
==================================================
 
Current Date and Time: 2025-02-15 08:08:08
=====================================================
 Start parsing input
=====================================================
Successfully loaded YAML file: config_test.yaml
Start validating keywords and checking potential conflict
Warning: permutation is required to be constrained,
                     molecular representation can currently ONLY be pip or graph,
                     change molecular representation to permutation invariant polynomials
                     of distances.
input feature automatically detected as 4
output target automatically detected as 3
edge feature automatically detected as 4
the currently only supported base_potential_type is atom+diatom
Warning:parametrically managed activation function's smooth boxcar function parameters
                     was not set up, we use a reasonable guess of it by setting it to -1.0, 4.0, 2.0
=====================================================
 Input file parsing finished
=====================================================
==========================================
           Loaded Configuration
==========================================
{
    "database_style": "canonical_xyz",
    "method": "CDNN",
    "permutation": "constrain",
    "permutation_order": 3,
    "permutation_pairs": [
        [
            1,
            2,
            3
        ]
    ],
    "mol_rep": "graph",
    "graph_rep": {
        "edge_type": [
            "cutoff"
        ],
        "node_features": [
            "ionization_energy",
            "atomic_number",
            "atomic_mass",
            "covalent_radius"
        ],
        "edge_features": [
            "distance",
            "angle",
            "dihedral_angle",
            "coulomb"
        ],
        "cutoff_radius": 6.0
    },
    "architecture": "mpnn",
    "random_seed": 12379,
    "train_dataset": "<MSLearn.dataset.XYZDataset object at 0x7f9f781ad6a0>",
    "diabatic_dataset": null,
    "permutation_dataset": null,
    "database": "sample.xyz",
    "training_target": "energy",
    "training_percent": 80,
    "batch_size": 2,
    "diabatic_restrain": false,
    "diabatic_database": null,
    "diabatic_weight": 1.0,
    "permutation_restrain": false,
    "permutation_database": null,
    "permutation_weight": 1.0,
    "topology_attention": false,
    "topology_attention_weight": 0.0004,
    "regularization": true,
    "regularization_weight": 1e-07,
    "gradient": false,
    "gradient_weight": 1.0,
    "nac": false,
    "nac_weight": 0.001,
    "num_epochs": 20,
    "learning_rate": 0.1,
    "optimizer_type": "adam",
    "scheduler_type": "step",
    "loss_threshold": 0.002,
    "early_stopping_patience": 10,
    "early_stopping_delta": 0.0002,
    "loss_function": "mse",
    "checkpoint_path": "checkpoint_test.pth",
    "print_interval": 1,
    "save_interval": 10,
    "input_dim": 4,
    "output_dim": 3,
    "hidden_layers": [
        10,
        5
    ],
    "activation": "gelu",
    "matrix_type": 5,
    "mpnn_structure": "nonlinear",
    "message_passing_network": [
        25,
        15
    ],
    "update_network": [
        12,
        8
    ],
    "edge_attr_dim": 4,
    "parametric_mode": true,
    "PM_config": {
        "base_potential_type": "atom+diatom",
        "R_indicator": null,
        "R_indicator_train_dataset": "tensor([[ 1.1381,  1.3333,  1.2761,  1.6095,  1.4714,  1.4142,  2.7208,  7.6667,\n          7.2705, 22.2076, 20.1849, 18.9737,  2.4939,  6.3333,  6.1969, 16.3669,\n         15.6803, 15.3414,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000],\n        [ 1.1381,  1.3333,  1.2761,  1.6095,  1.4714,  1.4142,  2.7208,  7.6667,\n          7.2705, 22.2076, 20.1849, 18.9737,  2.4939,  6.3333,  6.1969, 16.3669,\n         15.6803, 15.3414,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000],\n        [ 1.1429,  1.3469,  1.2857,  1.6382,  1.4898,  1.4286,  2.7152,  7.6402,\n          7.2381, 22.1102, 20.0613, 18.8350,  2.4889,  6.3068,  6.1723, 16.2594,\n         15.5847, 15.2511,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000],\n        [ 1.1428,  1.3469,  1.2857,  1.6382,  1.4898,  1.4286,  3.1060,  9.6542,\n          9.6441, 30.0276, 29.9655, 29.9335,  2.3141,  5.6315,  5.2998, 14.2546,\n         12.7873, 12.0027,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000]])",
        "R_indicator_permutation_dataset": null,
        "pm": [
            -1.0,
            4.0,
            2.0
        ],
        "base_potential": null,
        "base_potential_train_dataset": "tensor([[1.2300, 0.1200, 0.7800],\n        [1.3300, 1.1200, 1.7800],\n        [1.5000, 0.2200, 0.8500],\n        [1.5000, 0.2200, 0.8500]])",
        "base_potential_permutation_dataset": null
    },
    "repsentation": "pip"
}
Epoch 0 - True Loss Computed:Total_Training_Loss = 9170.5312500, Adiabatic_Loss = 9170.5312500, Loss_change (from batch) = -inf, Validation_Loss = 9025.4755859, Regularization_Term = 0.0000022, 
Checkpoint saved at epoch 0
Epoch 1 - True Loss Computed:Total_Training_Loss = 5436.6772461, Adiabatic_Loss = 5436.6772461, Loss_change (from batch) = -797.5585938, Validation_Loss = 4014.2277832, Regularization_Term = 0.0000032, 
Epoch 2 - True Loss Computed:Total_Training_Loss = 2915.4809570, Adiabatic_Loss = 2915.4809570, Loss_change (from batch) = 3910.1083984, Validation_Loss = 1665.1790771, Regularization_Term = 0.0000040, 
Epoch 3 - True Loss Computed:Total_Training_Loss = 6787.3076172, Adiabatic_Loss = 6787.3076172, Loss_change (from batch) = -7653.3813477, Validation_Loss = 7708.8803711, Regularization_Term = 0.0000045, 
Epoch 4 - True Loss Computed:Total_Training_Loss = 7519.6430664, Adiabatic_Loss = 7519.6430664, Loss_change (from batch) = 2186.1289062, Validation_Loss = 8671.6337891, Regularization_Term = 0.0000050, 
Epoch 5 - True Loss Computed:Total_Training_Loss = 7029.6147461, Adiabatic_Loss = 7029.6147461, Loss_change (from batch) = 242.8867188, Validation_Loss = 7991.1586914, Regularization_Term = 0.0000058, 
Epoch 6 - True Loss Computed:Total_Training_Loss = 9721.3681641, Adiabatic_Loss = 9721.3681641, Loss_change (from batch) = -1040.8413086, Validation_Loss = 4675.7397461, Regularization_Term = 0.0000070, 
Epoch 7 - True Loss Computed:Total_Training_Loss = 7311.7285156, Adiabatic_Loss = 7311.7285156, Loss_change (from batch) = 4293.6894531, Validation_Loss = 7449.6411133, Regularization_Term = 0.0000072, 
Epoch 8 - True Loss Computed:Total_Training_Loss = 7362.1074219, Adiabatic_Loss = 7362.1074219, Loss_change (from batch) = -3438.4746094, Validation_Loss = 7105.1420898, Regularization_Term = 0.0000078, 
Epoch 9 - True Loss Computed:Total_Training_Loss = 6826.7260742, Adiabatic_Loss = 6826.7260742, Loss_change (from batch) = -77.5751953, Validation_Loss = 6037.5249023, Regularization_Term = 0.0000086, 
Epoch 10 - True Loss Computed:Total_Training_Loss = 5533.4423828, Adiabatic_Loss = 5533.4423828, Loss_change (from batch) = -787.8510742, Validation_Loss = 3944.3483887, Regularization_Term = 0.0000095, 
Checkpoint saved at epoch 10
Epoch 11 - True Loss Computed:Total_Training_Loss = 4378.0830078, Adiabatic_Loss = 4378.0830078, Loss_change (from batch) = -1317.7250977, Validation_Loss = 2557.9423828, Regularization_Term = 0.0000104, 
Early stopping: No significant improvement in 10 epochs.
==========================================
           Training finished
==========================================
Trained model saved: output/trained_model.pth
Model configuration saved: output/model_config.json
Model configuration saved successfully at: output/model_config.yaml
Model configuration saved to output/model_config.json
Training history saved to output/training_history.csv
Training history saved to output/true_training_history.csv
Model summary saved: output/model_summary.txt
MPNN parameters saved: output/mpnn_params.txt

===All training outputs saved successfully!===

Current Date and Time: 2025-02-15 08:08:08

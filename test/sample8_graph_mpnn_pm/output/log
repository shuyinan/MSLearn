==================================================
  
 Multi-State Surface Learning (MSLearn) Package
  
==================================================
Authors: Yinan Shu, Donald G. Truhlar
        University of Minnesota
Version: 1.0
         Updated on Feb 14, 2025
  
Features of current version
    Available coordinate files:
        general, xyz, canonical_xyz
    Available network architecture: 
        feed-forward neural network
        message-passing neural network
    Available molecular representation:
        xyz, zmatrix, distance
        permutation invaraint polynomials (PIPs) of distances,
        graph
    Available methods:
        diabatization by deep neural network (DDNN)
        compatibilization by deep neural network (CDNN)
            with controllable matrix form
  
    physical properties:
        1. using permutation invariant molecular representation or
           a permuted database to constrain or restrain permutation symmetry
        2. using parametrically managed activation function to enforce
           correct behavior of potential energy surfaces (PESs) in asymptotic
           and/or repulsive regions
==================================================
 
Current Date and Time: 2025-02-15 08:17:08
=====================================================
 Start parsing input
=====================================================
Successfully loaded YAML file: config_test.yaml
Start validating keywords and checking potential conflict
Warning: permutation is required to be constrained,
                     molecular representation can currently ONLY be pip or graph,
                     change molecular representation to permutation invariant polynomials
                     of distances.
input feature automatically detected as 4
output target automatically detected as 3
edge feature automatically detected as 4
the currently only supported base_potential_type is atom+diatom
Warning:parametrically managed activation function's smooth boxcar function parameters
                     was not set up, we use a reasonable guess of it by setting it to -1.0, 4.0, 2.0
=====================================================
 Input file parsing finished
=====================================================
==========================================
           Loaded Configuration
==========================================
{
    "database_style": "canonical_xyz",
    "method": "CDNN",
    "permutation": "constrain",
    "permutation_order": 3,
    "permutation_pairs": [
        [
            1,
            2,
            3
        ]
    ],
    "mol_rep": "graph",
    "graph_rep": {
        "edge_type": [
            "cutoff"
        ],
        "node_features": [
            "ionization_energy",
            "atomic_number",
            "atomic_mass",
            "covalent_radius"
        ],
        "edge_features": [
            "distance",
            "angle",
            "dihedral_angle",
            "coulomb"
        ],
        "cutoff_radius": 6.0
    },
    "architecture": "mpnn",
    "random_seed": 12379,
    "train_dataset": "<MSLearn.dataset.XYZDataset object at 0x7fd132f3f050>",
    "diabatic_dataset": null,
    "permutation_dataset": null,
    "database": "sample.xyz",
    "training_target": "energy",
    "training_percent": 80,
    "batch_size": 2,
    "diabatic_restrain": false,
    "diabatic_database": null,
    "diabatic_weight": 1.0,
    "permutation_restrain": false,
    "permutation_database": null,
    "permutation_weight": 1.0,
    "topology_attention": false,
    "topology_attention_weight": 0.0004,
    "regularization": true,
    "regularization_weight": 1e-07,
    "gradient": false,
    "gradient_weight": 1.0,
    "nac": false,
    "nac_weight": 0.001,
    "num_epochs": 20,
    "learning_rate": 0.1,
    "optimizer_type": "adam",
    "scheduler_type": "step",
    "loss_threshold": 0.002,
    "early_stopping_patience": 10,
    "early_stopping_delta": 0.0002,
    "loss_function": "mse",
    "checkpoint_path": "checkpoint_test.pth",
    "print_interval": 1,
    "save_interval": 10,
    "input_dim": 4,
    "output_dim": 3,
    "hidden_layers": [
        10,
        5
    ],
    "activation": "gelu",
    "matrix_type": 3,
    "mpnn_structure": "nonlinear",
    "message_passing_network": [
        25,
        15
    ],
    "update_network": [
        12,
        8
    ],
    "edge_attr_dim": 4,
    "parametric_mode": true,
    "PM_config": {
        "base_potential_type": "atom+diatom",
        "R_indicator": null,
        "R_indicator_train_dataset": "tensor([[ 1.1381,  1.3333,  1.2761,  1.6095,  1.4714,  1.4142,  2.7208,  7.6667,\n          7.2705, 22.2076, 20.1849, 18.9737,  2.4939,  6.3333,  6.1969, 16.3669,\n         15.6803, 15.3414,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000],\n        [ 1.1381,  1.3333,  1.2761,  1.6095,  1.4714,  1.4142,  2.7208,  7.6667,\n          7.2705, 22.2076, 20.1849, 18.9737,  2.4939,  6.3333,  6.1969, 16.3669,\n         15.6803, 15.3414,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000],\n        [ 1.1429,  1.3469,  1.2857,  1.6382,  1.4898,  1.4286,  2.7152,  7.6402,\n          7.2381, 22.1102, 20.0613, 18.8350,  2.4889,  6.3068,  6.1723, 16.2594,\n         15.5847, 15.2511,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000],\n        [ 1.1428,  1.3469,  1.2857,  1.6382,  1.4898,  1.4286,  3.1060,  9.6542,\n          9.6441, 30.0276, 29.9655, 29.9335,  2.3141,  5.6315,  5.2998, 14.2546,\n         12.7873, 12.0027,  3.0956, 10.0000,  9.1652, 33.5401, 28.3714,  2.0000]])",
        "R_indicator_permutation_dataset": null,
        "pm": [
            -1.0,
            4.0,
            2.0
        ],
        "base_potential": null,
        "base_potential_train_dataset": "tensor([[1.2300, 0.1200, 0.7800],\n        [1.3300, 1.1200, 1.7800],\n        [1.5000, 0.2200, 0.8500],\n        [1.5000, 0.2200, 0.8500]])",
        "base_potential_permutation_dataset": null
    },
    "repsentation": "pip"
}
Epoch 0 - True Loss Computed:Total_Training_Loss = 9055.0283203, Adiabatic_Loss = 9055.0283203, Loss_change (from batch) = -inf, Validation_Loss = 11446.6914062, Regularization_Term = 0.0000019, 
Checkpoint saved at epoch 0
Epoch 1 - True Loss Computed:Total_Training_Loss = 8575.4003906, Adiabatic_Loss = 8575.4003906, Loss_change (from batch) = 17.4658203, Validation_Loss = 10467.9521484, Regularization_Term = 0.0000025, 
Epoch 2 - True Loss Computed:Total_Training_Loss = 5475.4228516, Adiabatic_Loss = 5475.4228516, Loss_change (from batch) = -1219.9863281, Validation_Loss = 9433.2255859, Regularization_Term = 0.0000034, 
Epoch 3 - True Loss Computed:Total_Training_Loss = 3141.2216797, Adiabatic_Loss = 3141.2216797, Loss_change (from batch) = 1638.3427734, Validation_Loss = 2256.5378418, Regularization_Term = 0.0000041, 
Epoch 4 - True Loss Computed:Total_Training_Loss = 30834.9843750, Adiabatic_Loss = 30834.9843750, Loss_change (from batch) = -4988.8085938, Validation_Loss = 95164.4687500, Regularization_Term = 0.0000047, 
Epoch 5 - True Loss Computed:Total_Training_Loss = 8978.3007812, Adiabatic_Loss = 8978.3007812, Loss_change (from batch) = 26424.3320312, Validation_Loss = 9099.1044922, Regularization_Term = 0.0000043, 
Epoch 6 - True Loss Computed:Total_Training_Loss = 9225.3945312, Adiabatic_Loss = 9225.3945312, Loss_change (from batch) = -22250.8867188, Validation_Loss = 9334.4619141, Regularization_Term = 0.0000043, 
Epoch 7 - True Loss Computed:Total_Training_Loss = 9274.7714844, Adiabatic_Loss = 9274.7714844, Loss_change (from batch) = 175.1328125, Validation_Loss = 9331.5205078, Regularization_Term = 0.0000045, 
Epoch 8 - True Loss Computed:Total_Training_Loss = 9379.3164062, Adiabatic_Loss = 9379.3164062, Loss_change (from batch) = 57.0195312, Validation_Loss = 9414.7226562, Regularization_Term = 0.0000048, 
Epoch 9 - True Loss Computed:Total_Training_Loss = 9524.2519531, Adiabatic_Loss = 9524.2519531, Loss_change (from batch) = 118.6064453, Validation_Loss = 9560.9091797, Regularization_Term = 0.0000052, 
Epoch 10 - True Loss Computed:Total_Training_Loss = 9602.5136719, Adiabatic_Loss = 9602.5136719, Loss_change (from batch) = 138.5107422, Validation_Loss = 9661.3984375, Regularization_Term = 0.0000056, 
Checkpoint saved at epoch 10
Epoch 11 - True Loss Computed:Total_Training_Loss = 9447.8281250, Adiabatic_Loss = 9447.8281250, Loss_change (from batch) = 42.9394531, Validation_Loss = 9448.9697266, Regularization_Term = 0.0000060, 
Epoch 12 - True Loss Computed:Total_Training_Loss = 8858.0878906, Adiabatic_Loss = 8858.0878906, Loss_change (from batch) = -207.5546875, Validation_Loss = 8444.6826172, Regularization_Term = 0.0000065, 
Early stopping: No significant improvement in 10 epochs.
==========================================
           Training finished
==========================================
Trained model saved: output/trained_model.pth
Model configuration saved: output/model_config.json
Model configuration saved successfully at: output/model_config.yaml
Model configuration saved to output/model_config.json
Training history saved to output/training_history.csv
Training history saved to output/true_training_history.csv
Model summary saved: output/model_summary.txt
MPNN parameters saved: output/mpnn_params.txt

===All training outputs saved successfully!===

Current Date and Time: 2025-02-15 08:17:09
